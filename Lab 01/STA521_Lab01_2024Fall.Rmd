---
title: "STA521_Lab01_2024_Fall"
author: "Justin Kao"
date: "`r Sys.Date()`"
output: html_document
---

```{=html}
<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

</style>
```

### Tasks


1. Load the dataset from [this link](https://github.com/justinkao44/STA521_Lab_Fall2024/blob/main/Lab%2001/Student_Performance.csv).

2. Create visualizations using `ggplot` and provide insights based on the visualizations.

3. Perform multiple linear regression.

4. Display the Q-Q plot for the residuals.



### 1. Load the dataset. Source: Kaggle

```{r}
rm(list=ls()) # Clear the environment
options(scipen = 20)
data <- read.csv("Student_Performance.csv", header = TRUE)
```

### 2. Library needed

```{r}
library(dplyr) # For data manipulation
library(ggplot2) # For data visualization
library(readr) # For reading CSV files 
library(ggcorrplot) #For checking Correlation Coefficient
library(lmtest)
```

### 3. Basic EDA

```{r}
# Check the structure of the dataset to ensure it has loaded correctly
str(data)
dim(data)
```

```{r}
# View the first few rows of the dataset
head(data)

# Summary statistics to get an overview of the dataset
summary(data)
```

### 4. Visualization

::: {.alert .alert-info}
<strong>Info!</strong> Before doing the regression, knowing the distribution of y is important
:::

#### 1. Histogram of Performance Index

-   If you only need to edit the title (keeping the x-axis and y-axis labels the same as the variable names or default settings), `ggtitle()` is the easiest way to do so.

```{r}
ggplot(data = data, aes(x = Performance.Index)) + 
  geom_histogram() +
  ggtitle("Histogram of Performance Index")
```

-   If you want to edit the title, subtitle, x-axis label, y-axis label, caption, or legend title (e.g., fill), then use the `labs()` function.

```{r}
ggplot(data, aes(x = Performance.Index)) +
  geom_histogram() +
  labs(x = "Performance Index",
       y = "Count",
       title = "Histogram of Performance Index",
       fill = "Legend Title",
       caption = "Source: Student Performance Dataset from Kaggle")
```

-   If you want to change the color, binwidth, or fill color of a histogram, use the geom_histogram() function.

```{r}
ggplot(data, aes(x = Performance.Index)) +
  geom_histogram(binwidth = 1, color = "red", fill = "green" ) +
  labs(x = "Performance Index",
       y = "Count",
       title = "Histogram of Performance Index",
       fill = "Legend Title",
       caption = "Source: Student Performance Dataset from Kaggle")
```

```{r}
ggplot(data, aes(x = Performance.Index)) +
  geom_histogram(binwidth = 1, alpha = 0.5, aes(fill = after_stat(count))) +
  scale_fill_gradient(low = "red", high = "green") +
  labs(title = "Histogram of Performance Index",
       x = "Performance Index",
       y = "Count",
       fill = "Number of obs",
       caption = "Source: Student Performance Dataset from Kaggle")
```

::: {.alert .alert-info} 
<strong>Info!</strong> Now, let's create some plots for the x variables to gain insights into the explanatory variables. 
:::

#### 2. Boxplot of Performance Index by Extracurricular Activities

```{r}
ggplot(data, aes(x = Extracurricular.Activities, y = Performance.Index)) +
  geom_boxplot() +
  labs(title = "Performance Index by Extracurricular Activities",
       x = "Extracurricular Activities", 
       y = "Performance Index",
       caption = "Source: Student Performance Dataset from Kaggle")
```
```{r}
ggplot(data, aes(x = Extracurricular.Activities, y = Performance.Index))+
  geom_boxplot(color = "red", fill = "green") +
  labs(title = "Performance Index by Extracurricular Activities",
       x = "Extracurricular Activities", 
       y = "Performance Index",
       caption = "Source: Student Performance from Kaggle") +
  scale_y_continuous(breaks = seq(0, max(data$Performance.Index), by = 5))
```

#### 3. Scatter Plots

```{r}
# Scatter plot between Hours Studied and Performance Index
ggplot(data, aes(x = Hours.Studied, y = Performance.Index)) +
  geom_point(color = "darkblue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Hours Studied vs Performance Index", 
       x = "Hours Studied", 
       y = "Performance Index")

# Scatter plot between Previous Scores and Performance Index
ggplot(data, aes(x = Previous.Scores, y = Performance.Index)) +
  geom_point(color = "darkgreen", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Previous Scores vs Performance Index", 
       x = "Previous Scores", 
       y = "Performance Index")
```


#### 4. Correlation coefficient 

```{r}
# Calculate correlation matrix
corr_matrix <- cor(data[, sapply(data, is.numeric)], use = "complete.obs")

# Plot correlation matrix heatmap
ggcorrplot(corr_matrix, method = "circle", lab = TRUE) +
  labs(title = "Correlation Matrix of Numerical Variables")
```


### 5. Multiple Linear Regression Model  

```{r}
model <- lm(Performance.Index ~ Hours.Studied + Previous.Scores + Sleep.Hours + 
              Sample.Question.Papers.Practiced + Extracurricular.Activities, 
            data = data)
```

```{r}
summary(model)
```
```{r}
plot(model, which = 1)  # Residuals vs Fitted
plot(model, which = 2)  # Normal Q-Q plot
```

```{r}
dwtest(model)
```

### 5. Model Fit Analysis

::: {.alert .alert-info}
<strong>Info!</strong> Based on the summary output of the Multiple Linear Regression (MLR) model, here is a brief introductory assessment of how well the model fits the data. The model appears to work well, as the dataset was purposefully designed to enhance explanatory power and help you build confidence in using R for regression analysis.
:::


#### 1. R-squared and Adjusted R-squared
- **Multiple R-squared: 0.9888**: This indicates that approximately 98.88% of the variance in the `Performance.Index` is explained by the model. This is a very high R-squared value, suggesting a good fit.
- **Adjusted R-squared: 0.9887**: The Adjusted R-squared is slightly lower but still very close to 1, indicating that the model is still a good fit even after adjusting for the number of predictors.

#### 2. F-statistic and p-value
- **F-statistic: 1.757e+05 on 5 and 9994 DF, p-value < 0.00000000000000022**: The F-statistic is very large, and the p-value is extremely small, indicating that the overall regression model is highly significant. This means that at least one of the predictors is significantly related to the `Performance.Index`.

#### 3. Coefficients and Significance
- All the predictors in the model have extremely low p-values (all < 0.001), indicating that each predictor is statistically significant in predicting `Performance.Index`.
- The estimates for each coefficient are substantial, suggesting that the predictors have a strong influence on `Performance.Index`.

#### 4. Residual Standard Error (RSE)
- **Residual standard error: 2.038**: This value gives an idea of the average distance that the observed values fall from the regression line. Given the scale of the data, this value seems reasonably small, indicating that the model's predictions are quite accurate.

#### 5. Residuals
- The distribution of residuals (Min, 1Q, Median, 3Q, Max) suggests that the residuals are fairly symmetric around zero, which is a good sign. However, a more detailed residual analysis (e.g., residual plots) would be needed to confirm that there are no patterns in the residuals that violate the assumptions of linear regression.

#### Conclusion
The model appears to fit the data very well, as indicated by the high R-squared values, significant predictors, and low residual standard error. However, itâ€™s important to perform further diagnostic checks, such as examining residual plots, checking for multicollinearity (using VIF), and ensuring the assumptions of linear regression are met (e.g., homoscedasticity, normality of residuals, independence).

If all these checks are satisfied, you can be confident that the model is well-fitted and reliable for making predictions.

